{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "\n",
    "# CSCI 3202, Spring 2020\n",
    "# Assignment 3\n",
    "# Due:  Wednesday 4 March 2020 by 11:59 PM\n",
    "\n",
    "<br>\n",
    "\n",
    "### Your name:\n",
    "\n",
    "<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some things that might be useful**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy as cp\n",
    "from scipy import stats\n",
    "from math import floor\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from time import time\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Problem 1 (35 points):  Playing \"intelligent\" Tic-Tac-Toe\n",
    "\n",
    "<img src=\"https://www.cookieshq.co.uk/images/2016/06/01/tic-tac-toe.png\" width=\"150\"/>\n",
    "\n",
    "<a id='p2a'></a>\n",
    "\n",
    "### (1a)   Defining the Tic-Tac-Toe class structure\n",
    "\n",
    "Fill in this class structure for Tic-Tac-Toe using what we did during class as a guide.\n",
    "* `moves` is a list of tuples to represent which moves are available. Recall that we are using matrix notation for this, where the upper-left corner of the board, for example, is represented at (1,1).\n",
    "* `result(self, move, state)` returns a ***hypothetical*** resulting `State` object if `move` is made when the game is in the current `state`\n",
    "* `compute_utility(self, move, state)` calculates the utility of `state` that would result if `move` is made when the game is in the current `state`. This is where you want to check to see if anyone has gotten `nwin` in a row\n",
    "* `game_over(self, state)` - this wasn't a method, but it should be - it's a piece of code we need to execute repeatedly and giving it a name makes clear what task the piece of code performs. Returns `True` if the game in the given `state` has reached a terminal state, and `False` otherwise.\n",
    "* `utility(self, state, player)` also wasn't a method earlier, but also should be.  Returns the utility of the current state if the player is X and $-1 \\cdot$ utility if the player is O.\n",
    "* `display(self)` is a method to display the current game `state`, You get it for free! because this would be super frustrating without it.\n",
    "* `play_game(self, player1, player2)` returns an integer that is the utility of the outcome of the game (+1 if X wins, 0 if draw, -1 if O wins). `player1` and `player2` are functional arguments that we will deal with in parts **2b** and **2d**.\n",
    "\n",
    "Some notes:\n",
    "* Assume X always goes first.\n",
    "* Do **not** hard-code for 3x3 boards.\n",
    "* You may add attributes and methods to these classes as needed for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, moves):\n",
    "        self.to_move = 'X'\n",
    "        self.utility = 0\n",
    "        self.board = {}\n",
    "        self.moves = cp.copy(moves)\n",
    "\n",
    "        \n",
    "class TicTacToe:\n",
    "    \n",
    "    def __init__(self, nrow=3, ncol=3, nwin=3, nexp=0):\n",
    "        self.nrow = nrow\n",
    "        self.ncol = ncol\n",
    "        self.nwin = nwin\n",
    "#        moves = # insert your general list of nrow x ncol moves here\n",
    "        moves = [(row, col) for row in range(1, nrow + 1) for col in range(1, ncol + 1)]\n",
    "        self.state = State(moves)\n",
    "        self.nexp = nexp\n",
    "\n",
    "    def result(self, move, state):\n",
    "        '''\n",
    "        What is the hypothetical result of move `move` in state `state` ?\n",
    "        move  = (row, col) tuple where player will put their mark (X or O)\n",
    "        state = a `State` object, to represent whose turn it is and form\n",
    "                the basis for generating a **hypothetical** updated state\n",
    "                that will result from making the given `move`\n",
    "        '''\n",
    "\n",
    "        # your code goes here\n",
    "        \n",
    "        # Solution:\n",
    "        # Don't do anything if the move isn't a legal one\n",
    "        if move not in state.moves:\n",
    "            return state\n",
    "        # Return a copy of the updated state:\n",
    "        #   compute utility, update the board, remove the move, update whose turn\n",
    "        new_state = cp.deepcopy(state)\n",
    "        new_state.utility = self.compute_utility(move, state)\n",
    "        new_state.board[move] = state.to_move\n",
    "        new_state.moves.remove(move)\n",
    "        new_state.to_move = ('O' if state.to_move == 'X' else 'X')\n",
    "        return new_state\n",
    "\n",
    "        \n",
    "    def compute_utility(self, move, state):\n",
    "        '''\n",
    "        What is the utility of making move `move` in state `state`?\n",
    "        If 'X' wins with this move, return 1;\n",
    "        if 'O' wins return -1;\n",
    "        else return 0.\n",
    "        '''        \n",
    "\n",
    "        # your code goes here\n",
    "\n",
    "        # Solution:\n",
    "        row, col = move\n",
    "        player = state.to_move\n",
    "        \n",
    "        # create a hypothetical copy of the board, with 'move' executed\n",
    "        board = cp.deepcopy(state.board)\n",
    "        board[move] = player\n",
    "\n",
    "        # what are all the ways 'player' could with with 'move'?\n",
    "        \n",
    "        # check for row-wise win\n",
    "        in_a_row = 0\n",
    "        for c in range(1,self.ncol+1):\n",
    "            in_a_row += board.get((row,c))==player\n",
    "\n",
    "        # check for column-wise win\n",
    "        in_a_col = 0\n",
    "        for r in range(1,self.nrow+1):\n",
    "            in_a_col += board.get((r,col))==player\n",
    "\n",
    "        # check for NW->SE diagonal win\n",
    "        in_a_diag1 = 0\n",
    "        for r in range(row,0,-1):\n",
    "            in_a_diag1 += board.get((r,col-(row-r)))==player\n",
    "        for r in range(row+1,self.nrow+1):\n",
    "            in_a_diag1 += board.get((r,col-(row-r)))==player\n",
    "\n",
    "        # check for SW->NE diagonal win\n",
    "        in_a_diag2 = 0\n",
    "        for r in range(row,0,-1):\n",
    "            in_a_diag2 += board.get((r,col+(row-r)))==player\n",
    "        for r in range(row+1,self.nrow+1):\n",
    "            in_a_diag2 += board.get((r,col+(row-r)))==player\n",
    "        \n",
    "        if self.nwin in [in_a_row, in_a_col, in_a_diag1, in_a_diag2]:\n",
    "            return 1 if player=='X' else -1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "\n",
    "    def game_over(self, state):\n",
    "        '''game is over if someone has won (utility!=0) or there\n",
    "        are no more moves left'''\n",
    "\n",
    "        # your code goes here\n",
    "        \n",
    "        # Solution:\n",
    "        return state.utility!=0 or len(state.moves)==0    \n",
    "\n",
    "    \n",
    "    def utility(self, state, player):\n",
    "        '''Return the value to player; 1 for win, -1 for loss, 0 otherwise.'''\n",
    "\n",
    "        # your code goes here\n",
    "        \n",
    "        # Solution:\n",
    "        return state.utility if player=='X' else -state.utility        \n",
    "        \n",
    "        \n",
    "    def display(self):\n",
    "        for row in range(1, self.nrow+1):\n",
    "            for col in range(1, self.ncol+1):\n",
    "                print(self.state.board.get((row, col), '.'), end=' ')\n",
    "            print()\n",
    "        \n",
    "    def play_game(self, player1, player2):\n",
    "        '''Play a game of tic-tac-toe!'''\n",
    "\n",
    "        # your code goes here\n",
    "\n",
    "        # Solution:\n",
    "        turn_limit = self.nrow*self.ncol  # limit in case of buggy code\n",
    "        turn = 0\n",
    "        while turn<=turn_limit:\n",
    "            for player in [player1, player2]:\n",
    "                turn += 1\n",
    "                move = player(self)\n",
    "                self.state = self.result(move, self.state)\n",
    "                if self.game_over(self.state):\n",
    "                    #self.display()\n",
    "                    return self.state.utility                \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "### (1b) Define a random player\n",
    "\n",
    "Define a function `random_player` that takes a single argument of the `TicTacToe` class and returns a random move out of the available legal moves in the `state` of the `TicTacToe` game.\n",
    "\n",
    "In your code for the `play_game` method above, make sure that `random_player` could be a viable input for the `player1` and/or `player2` arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_player(game):\n",
    "    '''A player that chooses a legal move at random out of all\n",
    "    available legal moves in Tic-Tac-Toe state argument'''\n",
    "\n",
    "    \n",
    "    # your code goes here...\n",
    "\n",
    "    # Solution:\n",
    "    possible_actions = game.state.moves\n",
    "    random_move = possible_actions[np.random.randint(low=0, high=len(possible_actions))]\n",
    "    \n",
    "    return random_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know from experience and/or because I'm telling you right now that if two `random_player`s play many games of Tic-Tac-Toe against one another, whoever goes first will win about 58% of the time.  Verify that this is the case by playing at least 1,000 games between two random players. Report the proportion of the games that the first player has won.\n",
    "\n",
    "**\"Unit tests\":** If you are wondering how close is close enough to 58%, I simulated 100 tournaments of 1,000 games each. The min-max range of win percentage by the first player was 54-63%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 1: %wins=56.9, %draws=14.4, %losses=28.7\n"
     ]
    }
   ],
   "source": [
    "# Solution:\n",
    "    \n",
    "wins = 0\n",
    "losses = 0\n",
    "draws = 0\n",
    "n_games = 1000\n",
    "for _ in range(n_games):\n",
    "    ttt = TicTacToe(3,3,3)\n",
    "    outcome = ttt.play_game(random_player, random_player)\n",
    "#    outcome = ttt.play_game(alphabeta_player, random_player)\n",
    "#    outcome = ttt.play_game(alphabeta_player, alphabeta_player)\n",
    "#    outcome = ttt.play_game(random_player, alphabeta_player)\n",
    "#    print(outcome)\n",
    "    if outcome==1:\n",
    "        wins += 1\n",
    "    elif outcome==0:\n",
    "        draws += 1\n",
    "    elif outcome==-1:\n",
    "        losses += 1\n",
    "\n",
    "print('Player 1: %wins={}, %draws={}, %losses={}'.format(100*wins/n_games, 100*draws/n_games, 100*losses/n_games))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "### (1c) What about playing randomly on different-sized boards?\n",
    "\n",
    "What does the long-term win percentage appear to be for the first player in a 4x4 Tic-Tac-Toe tournament, where 4 marks must be connected for a win?  Support your answer using a simulation and printed output, similar to **2b**.\n",
    "\n",
    "**Also:** The win percentage should have changed substantially. Did the decrease in wins turn into more losses for the first player or more draws? Write a few sentences explaining the behavior you observed.  *Hint: think about how the size of the state space has changed.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 1: %wins=31.4, %draws=43.9, %losses=24.7\n"
     ]
    }
   ],
   "source": [
    "# Solution:\n",
    "    \n",
    "wins = 0\n",
    "losses = 0\n",
    "draws = 0\n",
    "n_games = 1000\n",
    "for _ in range(n_games):\n",
    "    ttt = TicTacToe(4,4,4)\n",
    "    outcome = ttt.play_game(random_player, random_player)\n",
    "#    outcome = ttt.play_game(alphabeta_player, random_player)\n",
    "#    outcome = ttt.play_game(alphabeta_player, alphabeta_player)\n",
    "#    outcome = ttt.play_game(random_player, alphabeta_player)\n",
    "#    print(outcome)\n",
    "    if outcome==1:\n",
    "        wins += 1\n",
    "    elif outcome==0:\n",
    "        draws += 1\n",
    "    elif outcome==-1:\n",
    "        losses += 1\n",
    "\n",
    "print('Player 1: %wins={}, %draws={}, %losses={}'.format(100*wins/n_games, 100*draws/n_games, 100*losses/n_games))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "### (1d) Define an alpha-beta player\n",
    "\n",
    "Alright. Let's finally get serious about our Tic-Tac-Toe game.  No more fooling around!\n",
    "\n",
    "Craft a function called `alphabeta_player` that takes a single argument of a `TicTacToe` class object and returns the minimax move in the `state` of the `TicTacToe` game. As the name implies, this player should be implementing alpha-beta pruning as described in the textbook and lecture.\n",
    "\n",
    "Note that your alpha-beta search for the minimax move should include function definitions for `max_value` and `min_value` (see the aggressively realistic pseudocode from the lecture slides).\n",
    "\n",
    "In your code for the `play_game` method above, make sure that `alphabeta_player` could be a viable input for the `player1` and/or `player2` arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution:\n",
    "def random_player(game):\n",
    "    '''A player that chooses a legal move at random.'''\n",
    "    possible_actions = game.state.moves\n",
    "    return possible_actions[np.random.randint(low=0, high=len(possible_actions))]\n",
    "\n",
    "\n",
    "def alphabeta_player(game):\n",
    "    return alphabeta_search(game)\n",
    "\n",
    "def alphabeta_search(game):\n",
    "    '''search game approach to find best action, using alpha-beta pruning:\n",
    "    alpha = best (highest) move found so far for Max\n",
    "    beta  = best (lowest) move found so far for Min'''\n",
    "\n",
    "    player = game.state.to_move\n",
    "\n",
    "    # Functions used by alphabeta\n",
    "    def max_value(state, alpha, beta):\n",
    "        if game.game_over(state):\n",
    "            return game.utility(state, player)\n",
    "        value = -float('inf')\n",
    "        for a in state.moves:\n",
    "            \n",
    "            value = max(value, min_value(game.result(a, state), alpha, beta))\n",
    "            if value >= beta:\n",
    "                return value\n",
    "            alpha = max(alpha, value)\n",
    "        return value\n",
    "\n",
    "    def min_value(state, alpha, beta):\n",
    "        if game.game_over(state):\n",
    "            return game.utility(state, player)\n",
    "        value = float('inf')\n",
    "        for a in state.moves:\n",
    "            \n",
    "            value = min(value, max_value(game.result(a, state), alpha, beta))\n",
    "            if value <= alpha:\n",
    "                return value\n",
    "            beta = min(beta, value)\n",
    "        return value\n",
    "\n",
    "    # Body of alphabeta_cutoff_search:\n",
    "    best_score = -float('inf')\n",
    "    beta = float('inf')\n",
    "    best_action = None\n",
    "    for a in game.state.moves:\n",
    "        \n",
    "        value = min_value(game.result(a, game.state), best_score, beta)\n",
    "        if value > best_score:\n",
    "            best_score = value\n",
    "            best_action = a\n",
    "    return best_action\n",
    "\n",
    "###################################\n",
    "# def alphabeta_player(game):\n",
    "#     return alphabeta_search(game)\n",
    "\n",
    "# def alphabeta_search(game):\n",
    "#     '''search game approach to find best action, using alpha-beta pruning:\n",
    "#     alpha = best (highest) move found so far for Max\n",
    "#     beta  = best (lowest) move found so far for Min'''\n",
    "\n",
    "#     player = game.state.to_move\n",
    "\n",
    "#     # Functions used by alphabeta\n",
    "#     def max_value(state, alpha, beta):\n",
    "#         if game.game_over(state):\n",
    "#             return game.utility(state, player)\n",
    "#         value = -float('inf')\n",
    "#         for a in state.moves:\n",
    "#             game.nexp += 1\n",
    "#             value = max(value, min_value(game.result(a, state), alpha, beta))\n",
    "#             if value >= beta:\n",
    "#                 return value\n",
    "#             alpha = max(alpha, value)\n",
    "#         return value\n",
    "\n",
    "#     def min_value(state, alpha, beta):\n",
    "#         if game.game_over(state):\n",
    "#             return game.utility(state, player)\n",
    "#         value = float('inf')\n",
    "#         for a in state.moves:\n",
    "#             game.nexp += 1\n",
    "#             value = min(value, max_value(game.result(a, state), alpha, beta))\n",
    "#             if value <= alpha:\n",
    "#                 return value\n",
    "#             beta = min(beta, value)\n",
    "#         return value\n",
    "\n",
    "#     best_score = -float('inf')\n",
    "#     beta = float('inf')\n",
    "#     best_action = None\n",
    "#     for a in game.state.moves:\n",
    "#         game.nexp += 1\n",
    "#         value = min_value(game.result(a, game.state), best_score, beta)\n",
    "#         if value > best_score:\n",
    "#             best_score = value\n",
    "#             best_action = a\n",
    "#     return best_action, game.nexp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that your alpha-beta player code is working appropriately through the following tests, using a standard 3x3 Tic-Tac-Toe board. Run **only 10 games for each test**, and track the number of wins, draws and losses.\n",
    "\n",
    "1. An alpha-beta player who plays first should never lose to a random player who plays second.\n",
    "2. A random player who plays first should never win to an alpha-beta player who plays second.\n",
    "3. Two alpha-beta players should always draw.\n",
    "\n",
    "**Nota bene:** Test your code with fewer games between the players to start, because the alpha-beta player will require substantially more compute time than the random player.  This is why I only ask for 10 games, which still might take a minute or two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%wins=0.0, %draws=100.0, %losses=0.0\n",
      "Took 12.950598955154419 seconds\n"
     ]
    }
   ],
   "source": [
    "# Solution:\n",
    "\n",
    "tbeg = time()\n",
    "\n",
    "wins = 0\n",
    "losses = 0\n",
    "draws = 0\n",
    "n_games = 10\n",
    "for _ in range(n_games):\n",
    "    ttt = TicTacToe(3,3,3)\n",
    "#    outcome = ttt.play_game(random_player, random_player)\n",
    "#    outcome = ttt.play_game(alphabeta_player, random_player)\n",
    "    outcome = ttt.play_game(alphabeta_player, alphabeta_player)\n",
    "\n",
    "#    print(outcome)\n",
    "    if outcome==1:\n",
    "        wins += 1\n",
    "    elif outcome==0:\n",
    "        draws += 1\n",
    "    elif outcome==-1:\n",
    "        losses += 1\n",
    "\n",
    "tend = time()\n",
    "\n",
    "print('%wins={}, %draws={}, %losses={}'.format(100*wins/n_games, 100*draws/n_games, 100*losses/n_games))\n",
    "print('Took {} seconds'.format(tend-tbeg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "### (1e) What has pruning ever done for us?\n",
    "\n",
    "Calculate the number of number of states expanded by the minimax algorithm, with and without pruning, to determine the minimax decision from the initial 3x3 Tic-Tac-Toe board state.  This can be done in many ways, but writing out all the states by hand is **not** one of them (as you will find out!).\n",
    "\n",
    "Write a sentence or two, commenting on the difference in number of nodes expanded by each search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded by alpha-beta: 18296\n",
      "Expanded by minimax: 549945\n",
      "Percent savings from pruning: 0.9667312185764031\n"
     ]
    }
   ],
   "source": [
    "# Solution:\n",
    "#same code as above, but now including node expansion count\n",
    "\n",
    "def alphabeta_player(game):\n",
    "    return alphabeta_search(game)\n",
    "\n",
    "def alphabeta_search(game):\n",
    "    '''search game approach to find best action, using alpha-beta pruning:\n",
    "    alpha = best (highest) move found so far for Max\n",
    "    beta  = best (lowest) move found so far for Min'''\n",
    "\n",
    "    player = game.state.to_move\n",
    "\n",
    "    # Functions used by alphabeta\n",
    "    def max_value(state, alpha, beta):\n",
    "        if game.game_over(state):\n",
    "            return game.utility(state, player)\n",
    "        value = -float('inf')\n",
    "        for a in state.moves:\n",
    "            game.nexp += 1\n",
    "            value = max(value, min_value(game.result(a, state), alpha, beta))\n",
    "            if value >= beta:\n",
    "                return value\n",
    "            alpha = max(alpha, value)\n",
    "        return value\n",
    "\n",
    "    def min_value(state, alpha, beta):\n",
    "        if game.game_over(state):\n",
    "            return game.utility(state, player)\n",
    "        value = float('inf')\n",
    "        for a in state.moves:\n",
    "            game.nexp += 1\n",
    "            value = min(value, max_value(game.result(a, state), alpha, beta))\n",
    "            if value <= alpha:\n",
    "                return value\n",
    "            beta = min(beta, value)\n",
    "        return value\n",
    "\n",
    "    best_score = -float('inf')\n",
    "    beta = float('inf')\n",
    "    best_action = None\n",
    "    for a in game.state.moves:\n",
    "        game.nexp += 1\n",
    "        value = min_value(game.result(a, game.state), best_score, beta)\n",
    "        if value > best_score:\n",
    "            best_score = value\n",
    "            best_action = a\n",
    "    return best_action, game.nexp\n",
    "\n",
    "\n",
    "def minimax_player(game):\n",
    "    return minimax_search(game)\n",
    "\n",
    "def minimax_search(game):\n",
    "    '''same as alphabeta above, but no pruning'''\n",
    "\n",
    "    player = game.state.to_move\n",
    "\n",
    "    # Functions used by alphabeta\n",
    "    def max_value(state, alpha, beta):\n",
    "        if game.game_over(state):\n",
    "            return game.utility(state, player)\n",
    "        value = -float('inf')\n",
    "        for a in state.moves:\n",
    "            game.nexp += 1\n",
    "            value = max(value, min_value(game.result(a, state), alpha, beta))\n",
    "##            if value >= beta:\n",
    "##                return value\n",
    "            alpha = max(alpha, value)\n",
    "        return value\n",
    "\n",
    "    def min_value(state, alpha, beta):\n",
    "        if game.game_over(state):\n",
    "            return game.utility(state, player)\n",
    "        value = float('inf')\n",
    "        for a in state.moves:\n",
    "            game.nexp += 1\n",
    "            value = min(value, max_value(game.result(a, state), alpha, beta))\n",
    "##            if value <= alpha:\n",
    "##                return value\n",
    "            beta = min(beta, value)\n",
    "        return value\n",
    "\n",
    "    best_score = -float('inf')\n",
    "    beta = float('inf')\n",
    "    best_action = None\n",
    "    for a in game.state.moves:\n",
    "        game.nexp += 1\n",
    "        value = min_value(game.result(a, game.state), best_score, beta)\n",
    "        if value > best_score:\n",
    "            best_score = value\n",
    "            best_action = a\n",
    "    return best_action, game.nexp\n",
    "\n",
    "ttt = TicTacToe(3,3,3)\n",
    "move, nexp_alphabeta = alphabeta_player(ttt)\n",
    "print('Expanded by alpha-beta: {}'.format(nexp_alphabeta))\n",
    "ttt = TicTacToe(3,3,3)\n",
    "move, nexp_minimax = minimax_player(ttt)\n",
    "print('Expanded by minimax: {}'.format(nexp_minimax))\n",
    "print('Percent savings from pruning: {}'.format((nexp_minimax-nexp_alphabeta)/nexp_minimax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Problem 2 (30 points):  Uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2a) \n",
    "\n",
    "Suppose you are deciding when to arrive at a party. There is some optimal time to arrive when the loss you feel, as measured by _awkwardness_, is minimized at 0. That is, at some particular time, it is not awkward at all to show up to the party. The awkwardness (loss) increases as you arrive too early or too late relative to this optimal time. What is a suitable loss function, $L(d, x)$, to model this situation? Include definitions for $d$ and $x$, consistent with the examples from this class. Use this loss function this weekend when you go out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** Many possible answers. Anything that had a minimum of 0 when $d-x$ and increases as $|d-x|$ is okay.\n",
    "\n",
    "One possibility is quadratic loss: $ L(d, x) = (d-x)^2 $\n",
    "\n",
    "Another is absolute value loss: $L(d, x) = |d-x| $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2b)\n",
    "\n",
    "Suppose we have a situation where loss is given by the function $L(d, x) = 2(d-x)^2$. Set up, simplify, and evaluate integral(s) for the expected loss, $E_x[L(d, x)]$, where your prior beliefs regarding $x$ follow the distribution $f(x)$ given below. You may assume $f(x)=0$ for values of $x$ outside of the interval $[0, 3]$.\n",
    "\n",
    "f(x) =  \\begin{cases} \n",
    "      1/2 & 0 \\leq x <1 \\\\\n",
    "      3/8 & 1 \\leq x <2 \\\\\n",
    "      1/8 & 2 \\leq x \\leq 3 \n",
    "   \\end{cases}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "\\begin{align*}\n",
    "E_x[L(d,x)] &= \\int_{-\\infty}^{\\infty} L(d,x)f(x) dx \\\\\n",
    "            &= \\int_0^1 2(d-x)^2 \\cdot \\frac{1}{2} dx + \\int_1^2 2(d-x)^2 \\cdot \\frac{3}{8} dx + \\int_2^3 2(d-x)^2 \\cdot\\frac{1}{8} dx \\\\\n",
    "            &= \\int_0^1 (d-x)^2 dx + \\frac{3}{4} \\int_1^2 (d-x)^2 dx + \\frac{1}{4} \\int_2^3 (d-x)^2 dx \\\\\n",
    "            &= \\left (d^2 x - dx^2 + \\frac{1}{3} x^3 \\right )|_0^1 + \\frac{3}{4} \\left (d^2 x - dx^2 + \\frac{1}{3}x^3 \\right )|_1^2 + \\frac{1}{4} \\left (d^2 x - dx^2+\\frac{1}{3} x^3 \\right )|_2^3 \\\\\n",
    "            &= 2d^2 - \\frac{18}{4}d + \\frac{11}{3}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2c) \n",
    "\n",
    "Suppose our expected loss is represented by the function $E_x[(L(d,x)]=(2-d)^2+2$, and our prior beliefs regarding $x$ are given by the distribution $f(x)$ from part b.\n",
    "\n",
    "- Calculate Bayes' Decision, $d_{Bayes}$.\n",
    "\n",
    "- Calculate the Expected Value of Including Uncertainty, EVIU. Suppose that if we ignore uncertainty, our best guess for what decision to make is the median of $x$ (under our prior $f(x)$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "Bayes' Decision minimizes the expected loss, $d_{Bayes} = 2$.\n",
    "\n",
    "$EVIU = E_x[L(d_{iu},x)]-E_x[L(d_{Bayes},x)]$ and $d_{iu}=median(x)=1$, (half the probability mass on either side.)\n",
    "\n",
    "\\begin{align*}\n",
    "EVIU &= E_x[L(d_{iu},x)]-E_x[L(d_{Bayes},x)] \\\\\n",
    "     &= [(2-1)^2+2]-[(2-2)^2+2] \\\\\n",
    "     &= 1 \\\\\n",
    "\\end{align*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Problem 3 (35 points): Maximizing some objective function with a Genetic Algorithm\n",
    "\n",
    "Suppose we are trying to figure out a cookie recipe, but can't quite remember how much of each ingredient we need.\n",
    "\n",
    "So we want to maximize the following objective function corresponding to how close we are to this recipe:\n",
    "\n",
    "* 3/4 cup granulated sugar (36 tsp)\n",
    "* 3/4 cup packed brown sugar  (36 tsp)\n",
    "* 1 cup butter (48 tsp)\n",
    "* 1 teaspoon vanilla (1 tsp)\n",
    "* 1 egg\n",
    "* 2 1/4 cups flour (108 tsp)\n",
    "* 1 teaspoon baking soda (1 tsp)\n",
    "* 1/2 teaspoon salt (0.5 tsp)\n",
    "* 1 package (12 ounces) chocolate chips (2 cups) (96 tsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [36, 36, 48, 1, 1, 108, 1, 0.5, 96]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example starting state for a member of our population might look like: $state = [30, 30, 40, 1, 0, 100, 0.5, 0.5, 100]$\n",
    "\n",
    "### (3a) \n",
    "\n",
    "Write an objective function `def recipe_success(state)` that takes a single argument state, and returns the objective function value (fitness) of the state. The objective function should be maximized when a state reaches the target. You could for example define the fitness score of a particular state based on how far away each entry is from the target recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recipe_success(state):\n",
    "    target = [36, 36, 48, 1, 1, 108, 1, 0.5, 96]\n",
    "    \n",
    "    fitness = 0\n",
    "    for i in range(len(target)):\n",
    "        if target[i] == state[i]:\n",
    "            fitness += 100\n",
    "        else:\n",
    "            fitness = fitness\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing out the function\n",
    "# which is written to maximize\n",
    "\n",
    "state1 = [36,36,48,1,1,108,0.5,0.5,100]\n",
    "recipe_success(state1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3b) \n",
    "\n",
    "Using our in class notebook \"CSCI3202_GeneticAlgorithm.ipynb\" as your guide, write a genetic algorithm that starts with a population of 10 randomly generated \"recipes/states/members\" and uses the objective function you wrote in **(3a)** to hopefully hit the target after a certain number of generations. \n",
    "\n",
    "Key components of your code:\n",
    "- Generate the initial population randomly from numbers between 0 and 108 (half step intervals might be helpful since the recipe requires 1/2 tsp salt)\n",
    "- Allow for mutations in your population with an overall probability of mutation set to p = 0.1\n",
    "- Choose 2 \"parents\" in the generation of each \"child\"\n",
    "- Choose a random split point at which to combine the two \"parents\"\n",
    "- Run the algorithm for 200 iterations (\"generations\"). Do you hit your target?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "class problem:\n",
    "    \n",
    "    def __init__(self, initial_population, objective_function, mutation_probability, fitness_goal):\n",
    "        '''\n",
    "        initial_population = list of lists; each sub-list is a dna string for a population member\n",
    "        objective_function = objective function to maximize\n",
    "        mutation_probability = probability that any given child has a mutation\n",
    "        fitness_goal = fitness goal to achieve (stopping criterion, once member reaches this)\n",
    "        '''\n",
    "        self.population = initial_population\n",
    "        self.initial_population = initial_population\n",
    "        self.objective_function = objective_function\n",
    "        self.p_mutate = mutation_probability\n",
    "        self.n_pop = len(initial_population)\n",
    "        self.n_dna = len(initial_population[0])\n",
    "        self.fitness_goal = fitness_goal\n",
    "\n",
    "    def fitness(self):\n",
    "        '''\n",
    "        calculate each population member's probability of being selected for\n",
    "        reproduction based on performance on objective function\n",
    "        '''\n",
    "        performance = []\n",
    "        for k in range(self.n_pop):\n",
    "            performance.append(self.objective_function(self.population[k]))\n",
    "        \n",
    "            \n",
    "        total = sum(performance)\n",
    "        p_reproduce = [perf/total for perf in performance]\n",
    "        \n",
    "\n",
    "\n",
    "        return p_reproduce\n",
    "        \n",
    "    def reproduce(self, parent1, parent2):\n",
    "        # last DNA snippet from parent1:\n",
    "        split = np.random.randint(low=1, high=self.n_dna)\n",
    "        child = parent1[:split] + parent2[split:]\n",
    "        return child\n",
    "\n",
    "    def mutate(self, child):\n",
    "        # which gene to mutate?\n",
    "        gene = np.random.randint(low=0, high=self.n_dna)\n",
    "        if child[gene]==0:\n",
    "            child[gene]=1\n",
    "        elif child[gene]==1:\n",
    "            child[gene]=0\n",
    "        return child\n",
    "    \n",
    "def genetic_algorithm(problem, n_iter):\n",
    "    \n",
    "    for t in range(n_iter):\n",
    "        \n",
    "        new_generation = []\n",
    "        \n",
    "        for k in range(problem.n_pop):\n",
    "            \n",
    "            # select for reproduction\n",
    "            p_reproduce = problem.fitness()\n",
    "            #ind_parents = np.random.choice(range(0,problem.n_pop), size=2, replace=False)\n",
    "            ind_parents = np.random.choice(range(0,problem.n_pop), size=2, p=p_reproduce, replace=False)\n",
    "            parent1, parent2 = problem.population[ind_parents[0]], problem.population[ind_parents[1]]\n",
    "            \n",
    "            \n",
    "            # reproduce\n",
    "            child = problem.reproduce(parent1, parent2)\n",
    "            \n",
    "            # mutate\n",
    "            l_mutate = np.random.choice([True, False], p=[problem.p_mutate, 1-problem.p_mutate])\n",
    "            if l_mutate:\n",
    "                child = problem.mutate(child)\n",
    "            \n",
    "            # add to new generation\n",
    "            new_generation.append(child)\n",
    "        \n",
    "        # set problem.population = new generation\n",
    "        problem.population = new_generation\n",
    "        \n",
    "        # exit criterion check\n",
    "        performance = [problem.objective_function(member) for member in problem.population]\n",
    "        \n",
    "        best_member = max(zip(performance, problem.population))\n",
    "        \n",
    "        if best_member[0] >= problem.fitness_goal:\n",
    "            return best_member\n",
    "\n",
    "    print('reached n_iter', best_member)\n",
    "\n",
    "    return False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to create an initial population!\n",
    "initial_pop_number = 100\n",
    "\n",
    "gene_pool = np.arange(0,108,0.5)\n",
    "num_ingredients = 9\n",
    "\n",
    "initial_population = []\n",
    "\n",
    "for ii in range(initial_pop_number):\n",
    "    \n",
    "    new_member = []\n",
    "    for i in range(num_ingredients):\n",
    "        gene = np.random.choice(gene_pool, replace = True)\n",
    "        new_member.append(gene)\n",
    "    initial_population.append(new_member)\n",
    "    \n",
    "# print(initial_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached n_iter (500, [90.5, 36.0, 48.0, 1.0, 1.0, 45.5, 62.0, 46.5, 96.0])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "genetic_problem = problem(initial_population=initial_population, \n",
    "                          fitness_goal=900.0, \n",
    "                          mutation_probability=0.1, \n",
    "                          objective_function=recipe_success)\n",
    "out = genetic_algorithm(genetic_problem, 600)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3c)\n",
    "\n",
    "Report the following:\n",
    "- How many generations did it take to hit the goal?\n",
    "- If you change the initial population size to 100, does that change the number of generations it takes to achieve the goal recipe?\n",
    "- If you change the probability of mutation to 0.2, does that affect the number of generations it takes to achieve the goal recipe?\n",
    "\n",
    "Alternate questions to answer if Target not hit:\n",
    "- Report whether you minimized of maximized the objective function and whether that led to any major changes in how you designed the probability of reproduction. A couple sentences here is fine.\n",
    " \n",
    "- Report how many ingredients you ended up matching. e.g. target = [36, 36, 48, 1, 1, 108, 1, 0.5, 96], perhaps your algorithm achieved [36, 42, 8, 1, 1, 100, 56, 0.5, 0], then you would have matched 4 of the ingredient values.\n",
    " \n",
    "- Report how many iterations you tried in order to get this answer. (Don't burn up your machine in the process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are many possible solutions for this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I went up to 600 generations and never hit the target exactly. Above you can see that I matched 5 ingredients.I set up the objective function to be maximized.\n",
    "\n",
    "Changing the initial population size did not seem to help much. \n",
    "\n",
    "Changing the mutation probability also did not help a significant amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
